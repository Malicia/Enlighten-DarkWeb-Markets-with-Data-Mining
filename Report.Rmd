---
title: "Dark Web Market"
author: "Simon Delecourt & Edouard Donze"
output:
  html_notebook:
    code_folding: hide
    highlight: pygments
    number_sections: yes
    theme: readable
    toc: yes
    toc_float: yes
bibliography: My_bibliography.bibtex
---
<style>
body {text-align: justify}
</style>

# - Introduction
***

For the past few years, a lot of *web market* has been developed and you can now buy items of any kinds. However, plenty of those marketplaces are growing up on *dark web*. Even if government attempts to fight against this kind of illegal market, new one resurfaces or re-migrates frequently. On top of that, currently, we don't know enough of how these websites operate.

This paper presents a research carried out on one of the largest marketplace (specially for drugs) on Internet, the ***AlphaBay Dark Web Market***.  
Our work consists in analysing this market, its nature, its predominance of items, its different origins (countries), main sellers, and so on. Thus, during a first phase we perform some "Basic Statistics" on the *Data base*, in order to discover the marketplace and to point out its trend. Then, we present some experimental results of *data mining techniques* to discuss about them.


```{r Library, message=FALSE, warning=FALSE}
#----------------------------------------------------------
#                       Library :
#----------------------------------------------------------

#install.packages("stringr")
#install.packages("units")
#install.packages("ggmap")
#install.packages("plotrix")
#install.packages("rattle")
#install.packages("rpart")
#install.packages("rpart.plot")
#install.packages("RColorBrewer")
#install.packages("arules")
#install.packages("arulesViz")
#install.packages("e1071")
#install.packages("bnlearn")

# Mamipulation string
library(stringr)

# Using unit
library(units)

# Plot a map
library(ggmap)
library(plotrix)

# Decision Tree
library(rattle)
library(rpart)
library(rpart.plot)
library(RColorBrewer)

# Association rules
library(arules)
library(arulesViz)

# Bayesian classification, naive algorithm
library(e1071)

# Bayesian Network
library(bnlearn)

```

```{r Importation}
#----------------------------------------------------------
#               Importation of the data :
#----------------------------------------------------------

data <- as.data.frame(read.csv("../alphaClean.csv"))
```

# - Basic Statistics
***

## - General distribution

As we said before, we start by performing some basic statistics. Let's first analyse general distribution and trend of *AlphaBay Web Market*.

**1. Here, global view of ads distribution.**

```{r Number of ads}
#-----------------------------------------------
#      Number of ads in the world
#-----------------------------------------------

NumberOfAds <- function() {

  # Get rid of unwanted orign like Worldwide and Null which are not relevant
  matching_vector <- c(  !str_detect(data$origin, "Worldwide") & !str_detect(data$origin, "NULL"))
  
  sumup <- sort(summary(data[matching_vector, "origin"]), decreasing=TRUE)
  
  # Bar plot with the total number ofs ads in each country
  
  par(las=1)#display yaxis horizontally
  par(mar=c(6,8,4,3)) #give space for yaxis
  
  barp <- barplot(sumup[1:10], main="Number of ads in the World", xlim= c(0,max(sumup[1:10])+500), xlab="Number of ads",horiz = TRUE,  col = rainbow(10), cex.names = 0.8)
  
  # Ad numbers at the end of each bar
  barp <- text(y = barp, x = sumup[1:10], label = sumup[1:10], pos=4 , cex = 0.8, col= "black")
  
  # Frame
  box(which = "outer", lty = "solid")

}
  
NumberOfAds()

```
This bar-chart represents the 10 main countries in the world regarding the number of ads. As we can see, United States are the biggest dealer far ahead of the rest. Their number of ads is more than twice the number of the second one, which is United Kingdom.  
Moreover, we can notice that most of these countries belong to powerful area, that is to say countries from the north of America or from Europe, but we should not forget that China or Afghanistan are also present.

**2. Now let's have a look at the distribution of ads per category.**

```{r Function Select Drugs}
  selectDrug <- function(drugName){
    matching_vector <- c( (str_detect(data$category, drugName)))
    return(matching_vector)
  }
```

```{r Nb ads per categories}
#-----------------------------------------------
#      Number of ads per categories
#-----------------------------------------------

categ <- function(){
  
  cat <- c()

  for(i in 1:length(data$category)) {
    cat[i] <- unlist(strsplit(as.character(data$category[i]), "/"))[2]
    if(is.na(cat[i])) {cat[i] <- "Other Listings"}
  }
  
  tab_cat <- table(cat)
  tab_cat <- sort(tab_cat, decreasing=TRUE) 
  cat.data <- as.data.frame(tab_cat)
  
  radial.plot(cat.data$Freq,labels=cat.data$cat,label.prop=1.1,rp.type="r",start=5.6,clockwise=TRUE,lwd=4,line.col=rainbow(length(tab_cat)),main="Number of ads per categories",radial.labels=c(5,10,15,20))

  mtext("In thousands ads",side = 4,line=2,las=1,cex=1.08,font=3)
  
  # Frame
  box(which = "inner", lty = "solid")
  
}

categ()

```

```{r Categories rates}
RateDrugAd <- function() {

  rate <- c()
  
  NbAd <- nrow(data)
  
  # Select all "Drugs & Chemicals" ads
  matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
  drug.data <- data[matching_vector,]
  
  NbAdDrug <- nrow(drug.data)
  
  rate[1] <- round((NbAdDrug/NbAd)*100,2)
  
  # Select all "Fraud" ads
  matching_vector <- c( str_detect(data$category, "Fraud"))
  fraud.data <- data[matching_vector,]
  
  NbAdFraud <- nrow(fraud.data)
  
  rate[2] <- round((NbAdFraud/NbAd)*100,2)
  
  return(rate)
}

rate <- RateDrugAd()

```


To begin with, we can notice that there are 12 main categories in this web marketplace. It appears that *"Drugs and Chemicals"* group is the largest one. By the way, it represents `r rate[1]` % of the global market.  
It is also worth noting that the second most popular category is *"Fraud"*, that is to say all the ads regarding impersonation, deception papers and accounts. It represents `r rate[2]` % of the market, which is smaller than the Drug market. Eventually, we can notice that all the other items (digital product, weapons, jewelry ...) represent less than five percent of the marketplace.

## - Drug Market

*AlphaBay Web Market* is a well known place for dealing drugs. This last chart has proved that. Thus, let's focus on the drug market.

**1. You can see here the different distributions of drugs.**

```{r Distribution of Drugs}
#-----------------------------------------------
#      Distribution of Drugs in the market
#-----------------------------------------------

DistributionDrugs <- function() {

  #----------------------------
  #   The most common drugs
  #----------------------------
  
  drugs <- c("Cocaine", "Meth", "LSD", "Opioids", "Cannabis", "Steroids", "Ecstasy", "Ketamine", "Heroin", "Shrooms", "Tobacco", "Benzos", "Paraphernalia")
  
  freq <- c()
  for(i in 1:length(drugs)){
    matching_vector <- selectDrug(drugName=drugs[i]);
    sumup<-summary(matching_vector)
    freq[i] <- sumup[3]
  }
  
  freq <- as.numeric(freq)
  res <- data.frame(drugs, freq)
  res <- res[order(res$freq, decreasing = TRUE),]
  
  #----------------------
  #     Pie Chart 
  #----------------------
  
  # 1- Labels :
  # Calculation in percentage
  piepercent<- round(100*res$freq/sum(res$freq), 1)
    # round(a,1) : one digit after the comma
  
  lab <- c()
  
  for(i in 1:length(piepercent)) {
    lab[i] <- paste(piepercent[[i]], "%", sep=" ")
  }
  
  # 2- Title :
  title <- "Distribution of drugs"
  
  # 3- Colors :
  c <- rainbow(length(piepercent))
  
  # 4- Plot :
  pie3D(piepercent,labels = lab,labelcex = 1, main = title ,col=c, theta = 0.9, explode = 0.04)
  
  # 5- Legend :
  legend(x=-2.5,y=-1.1,res$drugs, cex = 0.9, fill = c,ncol=5,border=NA, xpd=NA)
  
  # Frame
  box(which = "inner", lty = "solid")
}

DistributionDrugs()

```

We can discern a large range of drugs categories. Nevertheless, *Cannabis*, *Opioids* and *Ecstay* cover more than 50 % of the market. The remaining is splited by all the other drugs.

**2. World distribution of drugs**

```{r Number of ads of Drugs}
#---------------------------------------------
#    Number of ads of Drugs in the world
#---------------------------------------------

NumberOfAdsDrugs <- function(){

  # Get rid of unwanted orign like Worldwide and Null which are not relevant
  matching_vector <- c( str_detect(data$category, "Drugs") & !str_detect(data$origin, "Worldwide") & !str_detect(data$origin, "NULL"))
  
  sumup <- sort(summary(data[matching_vector, "origin"]), decreasing=TRUE)
  
  # Bar plot with the total number of ads of Drugs in each country
  par(las=1)#display yaxis horizontally
  par(mar=c(6,8,3,3)) #give space for yaxis
    
  barp <- barplot(sumup[1:10], main="Number of ads of Drugs in the World", xlab="Number of ads",xlim = c(0,max(sumup[1:10]+500)),  col = rainbow(10), cex.names = 0.8, horiz = TRUE)
  barp <- text(y = barp, x = sumup[1:10], label = sumup[1:10], pos=4 , cex = 0.8, col= "black")
  
  # Frame
  box(which = "outer", lty = "solid")

}

NumberOfAdsDrugs()

```

Once more, we are plotting the 10 main dealer-countries in the world but this time regarding the number of drugs ads. At first sight, the chart looks like the first one. This is coherent, indeed, comparing the ratio between drugs ads and the total number of ads, we deduce that they are mainly dealing drugs.  
This also matches with the second chart that shows us that drugs are the main item in the market. There are few exceptions such as *Afghanistan* which has been replaced by *Spain* and *Canada* has been reversed with *China*.  
But what we can conclude so far is that the market of drugs is gathered in Europe and the north of America.

**3. Take a global view of the drugs market in Europe with the following map.**

```{r Europe Map, message=FALSE}

MapEurope <- function() {

  # Select the ads about drugs and get rid of the irrelevant orign Worlwide
  matching_vector <- c( (str_detect(data$category, "Drugs") ) & !str_detect(data$origin, "Worldwide"))
  
  sumup <- sort(summary(data[matching_vector, "origin"]), decreasing=TRUE)
  
  # Read a file containing the latitude and longitude of the "center" of each country
  data_country <- read.csv("./Stats/lat_long.csv")
  lat_long <- data.frame(Country = data_country$Country , long=  data_country$Longitude..average., lat=  data_country$Latitude..average.)
  
  # Create a data.frame with the name of the country and its nb of ads
  v <- data.frame(name= names(sumup) , amount = sumup)
  
  # Merge v with lat_long in order to have a data with Country/NbofAds/lattitude/longitude
  data_plot <- merge(v, lat_long,  by.x = "name", by.y = "Country" )
  
  # Create a map of EUROPE with circles showing the amount of ads
  map <- get_map(location = 'Europe', zoom =4 )
  mapPoints <- ggmap(map)  + xlab("") + ylab("") + ggtitle("Number of ads of Drugs in Europe")+
    geom_point(data = data_plot,aes(x =long, y = lat, size =amount)) +scale_size_continuous(limits=c(0,3000),breaks=c(0,500,1000,1500,2000), range = c(0,13)) 
  
  # Display
  mapPoints

}

MapEurope()

```

Circles show the amount of ads about drugs. The map confirms our assumptions that there are a lot of Drug dealers in Europe with, as major dealers countries, *United Kingdom*, *Netherlands* and *Germany*.

## - Countries Flows

Let's now focus more specifically on different countries and study their trend. To do so, we have had a look to export and import flows of the country.

**1. United Kingdom exportation**

The pie below represents the repartition of each category that United Kingdom exports. We focused on the second subcategory which appears to be the most relevant since the first one only gives information on the nature of the ad (for instance *"Drugs & Chemicals"*).

```{r Exportation UK}
#-----------------------------------------------
#   Importation / Exportation of a country
#-----------------------------------------------

country_Export <- function() {

  #-------------------
  #  Initialization
  #-------------------

  country <- "United Kingdom"
  num <- 0
  
  # Importation / Exportation :
  if (num == 0) { 
    way <- "origin"
    txt <- "- Exportation"
  } else if (num == 1) {
    way <- "destination"
    txt <- "- Importation"
  }
  
  #------------------
  #    Analysis
  #------------------
  
  # Country as destination
  matching_vector <- str_detect(data[,way], country)
  
  # list of the categories (among the line that have "Country" as origin)
  # -> Products (categories) exporting by the country 
  country_cat <- data[matching_vector,"category"] 
  
  # Handling of this categories
  # Regular expression for spliting the categories
  regex <- "/(.*)/(.*)/(.*)"
  cat <- str_match(country_cat, regex)
  
  # Counting this categories 
  tab <- table(cat[,3])   #cat[,3] : 2nd category 
  tab <- sort(tab, decreasing = TRUE)  # Sorting (biggest in first) 
  tab <- tab[1:10] # Taking only the most important
  
  #-----------------
  #    Pie Chart     
  #-----------------
  
  # 1- Labels :
  # Calculation in percentage
  piepercent<- round(100*tab/sum(tab), 1)
     # round(a,1) : one digit after the comma
  
  lab <- c()
  
  for(i in 1:length(piepercent)) {
    lab[i] <- paste(piepercent[[i]], "%", sep=" ")
  }
  
  # 2- Title :
  title <- paste(country, txt, sep=" ")
  
  # 3- Colors :
  c <- rainbow(length(piepercent))
 
  # 4- Plot :
  pie3D(piepercent,labels = lab,labelcex = 1, main = title ,col=c, theta = 0.9, explode = 0.04)
  
  # 5- Legend :
  legend(x=-2.3,y=-1.1,names(piepercent), cex = 0.8, fill = c,ncol=4,border=NA, xpd=NA)
  
  # Frame
  box(which = "inner", lty = "solid")
}

country_Export()
```

Given that most of exported items are drugs, that is not surprising they are the most sold product as we saw it before. Once again this pie chart shows the market diversity. Although a huge part concerns *"Cannabis & Hashish"* category, we can notice that *"Stimulants"* and other highly dangerous drugs are significantly present.  
We took the example of *United Kingdom* but most of European countries follows the same rules and this confirms our previous assumptions.

**2. Let's have a look at the exportations of Afghanistan which seem different to United Kingdom :**


```{r Exportation China}
#-----------------------------------------------
#   Importation / Exportation of a country
#-----------------------------------------------

country_Export <- function() {

  #-------------------
  #  Initialization
  #-------------------

  country <- "Afghanistan"
  num <- 0
  
  # Importation / Exportation :
  if (num == 0) { 
    way <- "origin"
    txt <- "- Exportation"
  } else if (num == 1) {
    way <- "destination"
    txt <- "- Importation"
  }
  
  #------------------
  #    Analysis
  #------------------
  
  # Country as destination
  matching_vector <- str_detect(data[,way], country)
  
  # list of the categories (among the line that have "Country" as origin)
  # -> Products (categories) exporting by the country 
  country_cat <- data[matching_vector,"category"] 
  
  # Handling of this categories
  # Regular expression for spliting the categories
  regex <- "/(.*)/(.*)/(.*)"
  cat <- str_match(country_cat, regex)
  
  # Counting this categories 
  tab <- table(cat[,3])   #cat[,3] : 2nd category 
  tab <- sort(tab, decreasing = TRUE)  # Sorting (biggest in first) 
  tab <- tab[1:10] # Taking only the most important
  
  #-----------------
  #    Pie Chart     
  #-----------------
  
  # 1- Labels :
  # Calculation in percentage
  piepercent<- round(100*tab/sum(tab), 1)
     # round(a,1) : one digit after the comma
  
  lab <- c()
  
  for(i in 1:length(piepercent)) {
    lab[i] <- paste(piepercent[[i]], "%", sep=" ")
  }
  
  # 2- Title :
  title <- paste(country, txt, sep=" ")
  
  # 3- Colors :
  c <- rainbow(length(piepercent))
 
  # 4- Plot :
  pie3D(piepercent,labels = lab,labelcex = 1, main = title ,col=c, theta = 0.9, explode = 0.04)
  
  # 5- Legend :
  legend(x=-2,y=-1,names(piepercent), cex = 0.8, fill = c,ncol=3,border=NA, xpd=NA)

  # Frame
  box(which = "inner", lty = "solid")
  
}

country_Export()
```

What's suprising is that, unlike most of countries, *Afghanistan* doesn't really export drugs. Actually, a vast majority of exported products are false identity, deception account... We may undeline that *Afghanistan* is also dealing electronic devices or softwares.

**3. Let's compare France export & import flows and see if there is a difference between them.**

```{r Export_Import FR}

  #-----------------------------------------------
  #   Importation / Exportation of a country
  #-----------------------------------------------
  
Country_Export_Import <- function() {

    #-------------------
    #  Initialization
    #-------------------
    
    country <- "France"
    
    #---------------------------
    #    Analysis - Exportation
    #---------------------------
    
    # Country as origin
    matching_vector <- str_detect(data[,"origin"], country)
    
    # list of the categories (among the line that have "Country" as origin)
    # -> Products (categories) exporting by the country 
    country_cat <- data[matching_vector,"category"] 
    
    # Handling of this categories
    # Regular expression for spliting the categories
    regex <- "/(.*)/(.*)/(.*)"
    cat <- str_match(country_cat, regex)
    
    # Counting this categories 
    tab_exp <- table(cat[,3])   #cat[,3] : 2nd category 
    tab_exp <- sort(tab_exp, decreasing = TRUE)  # Sorting (biggest in first) 
    tab_exp <- tab_exp[1:10] # Taking only the most important
    
    #---------------------------
    #    Analysis - Importation
    #---------------------------
    
    # Country as destination
    matching_vector <- str_detect(data[,"destination"], country)
    
    # list of the categories (among the line that have "Country" as destination)
    # -> Products (categories) importing by the country 
    country_cat <- data[matching_vector,"category"] 
    
    # Handling of this categories
    # Regular expression for spliting the categories
    regex <- "/(.*)/(.*)/(.*)"
    cat <- str_match(country_cat, regex)
    
    # Counting this categories 
    tab_imp <- table(cat[,3])   #cat[,3] : 2nd category 
    tab_imp <- sort(tab_imp, decreasing = TRUE)  # Sorting (biggest in first) 
    tab_imp <- tab_imp[1:10] # Taking only the most important
    
    #-------------------------
    #    Analysis - Fusion
    #-------------------------
    
    # Transformation in data frame
    tab_exp <- as.data.frame(tab_exp)
    tab_imp <- as.data.frame(tab_imp)
    
    # Merger of the 2 data frame in order to have the same labels 
    tab <- merge(tab_exp,tab_imp,by.x="Var1",by.y="Var1",all = TRUE)
    
    # Handling of the "NA" value (substitution by 0)
    for (j in 2:3) {
      for(i in 1:length(tab[,j])){
        if(is.na(tab[i,j])) {tab[i,j] <-0}
      }
    }  
    
    #---------------------------
    #    Pie Chart - Exporation     
    #---------------------------
    
    # ploting 2 graphics om the same picture
    par(mfrow = c(1,2))
    
    # 1- Labels :
    # Calculation in percentage
    piepercent <- round(100*tab[,2]/sum(tab[,2]), 1)
    # round(a,1) : one digit after the comma
    
    lab <- c()
    
    for(i in 1:length(piepercent)) {
      if(piepercent[[i]] == 0) {lab[i] <- ""} 
      else {lab[i] <- paste(piepercent[[i]], "%", sep=" ")}
    }

    # 2- Colors :
    c <- rainbow(length(tab[,1]))
    
    # 3- Plot :
    pie(piepercent,labels=lab,col=c)
    mtext("Exportation",cex=1)
    
    #----------------------------
    #    Pie Chart - Importation     
    #----------------------------
    
    # 1- Labels :
    # Calculation in percentage
    piepercent <- round(100*tab[,3]/sum(tab[,3]), 1)
    # round(a,1) : one digit after the comma
    
    lab <- c()
    
    for(i in 1:length(piepercent)) {
      if(piepercent[[i]] == 0) {lab[i] <- ""}
      else {lab[i] <- paste(piepercent[[i]], "%", sep=" ")}
    }

    # 2- Plot :
    pie(piepercent, labels=lab, col=c)
    mtext("Importation",cex=1)
    
    #------------------
    #   General - Plot     
    #-----------------
    
    par(oma=c(0,0,1.8,0))
    title("France",outer=TRUE)
    legend(x=-4,y=-1.1,tab[,1], cex = 0.8, fill=c,ncol=3,border=NA, xpd=NA)
    
    # Frame
    box(which = "outer", lty = "solid")
    
}

Country_Export_Import()
    
```

It is noticeable that both pies are different. The percentages of each category are not equal and some of them don't appear systematicaly in the other pie chart. However it is obvious that significant exported drugs are also imported. Morevover, *France* is importing some drugs that are not local.   
Nevertheless we have to moderate our conclusions since targeting one particular country reduces significantly the number of information we use for statistics.

## - Market prices

After analysing general trend and flows, one interesting topic to analyse is market prices. We wondered if sold products in *AlphaBay* are cheaper than in the streets. 

**1. Average prices on the *AlphaBay Web Market* **

Firstly, we calculated the average price of one gram of the most common drugs and we obtained the result below.

```{r Drugs Prices}

DrugsPrices <- function() {
  
  drugs <- c("Cocaine", "Meth", "Opioids", "Cannabis", "Steroids", "Ecstasy", "Ketamine", "Heroin",  "NBOME","Shrooms", "Tobacco", "Benzos", "Paraphernalia")
  
  med <-c()
  for(i in 1:length(drugs)){
    matching_vector <- selectDrug(drugName =  drugs[i]);
    med[i] <- median((data[matching_vector, "priceUnitDose"]))
  }
  priceDrugs <- data.frame(drugs, med); 
  
  priceDrugs$med <- round(priceDrugs$med,2)
  
  priceDrugs <- priceDrugs[order(priceDrugs$med, decreasing=TRUE), ]
  
  par(las=1) # Display yaxis horizontally
  par(mar=c(4,8,3,2)) # Give space for yaxis
  
  barp <- barplot(priceDrugs$med, main="Average Price of Drugs per Gram", names.arg = priceDrugs$drugs, xlim = c(0,max(priceDrugs$med+100)), cex.names = 0.8, col =rainbow(length(priceDrugs$drugs)), horiz =TRUE)
  barp <- text(y = barp, x = priceDrugs$med, label = paste(priceDrugs$med, " $", sep=""), pos=4 , cex = 0.8, col= "Black")
  
  # Frame
  box(which = "outer", lty = "solid")
  
  return (priceDrugs)

}

priceDrugs <- DrugsPrices()
```


**2. Comparison with the "street"**

Finally, we were looking to some information about prices of street sellers for same drugs as above. Thus, we gathered data in articles and websites. Unfortunately, we failed to obtain them on some drugs. Below is the result of what we found.


```{r Comparison articles & data, message=FALSE, warning=FALSE}

#-----------------------------------------
#   Prices find on articles
#-----------------------------------------

DrugsPricesDoc <- function(){
  
  cols <- c("Cocaine", "Meth", "Opioids",      "Cannabis"      , "Steroids", "Ecstasy", "Ketamine", "Heroin",  "NBOME","Shrooms", "Tobacco", "Benzos", "Paraphernalia" , "MDMA", "Amphetamine", "Crack", "LSD"   , "URL")

  ref1  <- c(    35   ,   200  ,     NA   ,     (5.3 + 7.85)/2   ,    NA     ,     15   ,     25    ,    100   ,     NA  ,    NA   ,    NA    ,     NA  ,        NA      ,    40 ,   5         ,  NA    ,  NA     ,   "http://www.drugwise.org.uk/how-much-do-drugs-cost/")
  ref2  <- c(    67   ,   NA   ,     NA   ,      51              ,    NA     ,     15   ,     32    ,    129   ,     NA  ,    NA   ,    NA    ,     NA  ,        NA      ,   51  ,   15        ,  97    ,  NA     , "http://www.telegraph.co.uk/news/uknews/crime/11346133/The-cost-of-street-drugs-in-Britain.html")
  ref3  <- c(    110  ,   80   ,     NA   ,      NA              ,    NA     ,     NA   ,     NA    ,    170   ,     NA  ,    5.7  ,    NA    ,     NA  ,        NA      ,  150  ,   NA        ,   NA   ,  12000  ,   "http://www.rehabcenter.net/the-average-cost-of-illegal-drugs-on-the-street/ " )
  ref4  <- c(    80   ,   109  ,     NA   ,      NA              ,    NA     ,   19.12  ,     NA    ,    91.16 ,     NA  ,    NA   ,    NA    ,     NA  ,        NA      ,    NA ,   NA        ,   NA   ,     NA  ,   " http://o.canada.com/business/interactive-what-illegal-drugs-cost-on-the-street-around-the-world")
  ref5  <- c(     64  ,   NA   ,     NA   ,      NA              ,    NA     ,     20   ,     NA    ,    NA    ,     NA  ,    NA   ,    NA    ,     NA  ,        NA      ,    NA ,   NA        ,  NA    ,   NA    , " http://www.thestudentpocketguide.com/2012/01/student-life/health-and-relationships/facts-about-drugs/")
  
  doc_drugs <- t(data.frame(ref1, ref2, ref3, ref4, ref5))
  colnames(doc_drugs) <- cols
  
  # Calculate the mean price of each drugs find on articles
  price_doc <- c()
  for(i in 1 : length(cols)){
    price_doc[i] <- summary(as.numeric(doc_drugs[,i]))[[4]]
  }
  price_doc.data <- data.frame(cols, price_doc)
  
  
  # Merge the previous dataframe which correspond to the mean price of each drugs in the data
  # with the dataframe created above
  beside_plot <- merge(price_doc.data, priceDrugs, by.x ="cols", by.y ="drugs") 
  
  rownames(beside_plot) <- beside_plot[,1]
  beside_plot <- beside_plot[,-1]
  
  # Creating the barplot
  par(las=1)#display yaxis horizontally
  par(mar=c(6,8,4,3)) # Give space for yaxis
 
  b <- barplot(rbind(beside_plot[,1], beside_plot[,2]), main="Average price of Drugs", xlim = c(0, 400),
          xlab="Price of Drugs", beside=TRUE, names.arg = rownames(beside_plot), col=1:2, horiz = TRUE, space = c(0,0.4), cex.names = 0.8)
  
  axis(side=1,at=c(50,150,250,350),labels=c(50,150,250,350))
  
  
  lab <- c("Street", "AlphaBay")
  
  legend("topright",lab,fill=1:2, cex=0.8)
  
  # Frame
  box(which = "outer", lty = "solid")
}

DrugsPricesDoc()

```

Globally, it appears that prices of street sellers are often largely higher than *AlphaBay* ads. In few cases both prices tend to be similar.

@DrugWise, @tele

# - Data mining
***

Secondly, we have performed some data mining techniques in order to discover hidden rules and correlations in the database and also to predict the value of one variable given other values.

## - Decision tree

```{r DTsellers}
#----------------------------------------------------------------------
#                  Decision tree - CART algorithm
#   Prediction of the seller knowing the price / category / origin
#                               Plot
#-----------------------------------------------------------------------

Dtsellers <- function(){  

  #-----------------
  #   New Data 
  #-----------------
  
  # Select all "Drugs & Chemicals" ads
  matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
  dectree.data <- data[matching_vector,]
  
  # Select the column of the data that are interesting for the tree
  # ie removing colunm like "id" or "url" that don't give any informations
  dectree.data <- subset(dectree.data, select=c(origin,category,seller,priceUnitDose))
  # Subset : choose the colunm that you want
  
  # Handling : column categorie
  # Regular expression for spliting the categories
  regex <- "/(.*)/(.*)/(.*)"
  cat <- str_match(dectree.data$category, regex)
  dectree.data$category <- cat[,3] # keep only the second part
  
  # Handling : seller
  tab_sel <- table(dectree.data$seller)
  tab_sel <- sort(tab_sel, decreasing=TRUE)  # Sorting (biggest in first)
  tab_sel <- tab_sel[1:5] # Taking only the most important : main sellers
  name_sel <- names(tab_sel)
  # New data keeping only the main sellers
  dectree.data <-subset(dectree.data, seller %in% name_sel) 
  
  # Random rows :
  dectree.data <- dectree.data[sample(nrow(dectree.data),nrow(dectree.data),replace=FALSE), ]
  
  #---------------------
  #   Decision tree
  #---------------------
  
  # Factor
  dectree.data$seller <- factor(dectree.data$seller)
  
  # Half of the data for making the decision tree
  train.data <- dectree.data[1:(floor(nrow(dectree.data))/2),]
  
  # Creation of the tree
  tree <- rpart(seller ~.,data=train.data, method="class") 
  
  # Plot
  fancyRpartPlot(tree)

  # Frame
  box(which = "outer", lty = "solid")
  
  #--------------------
  #   Prediction
  #--------------------
  
  # The other half for the prediction
  pred.data <- dectree.data[(floor(nrow(dectree.data)/2)+1):nrow(dectree.data),]
  
  # Making prediction
  pred <- predict(tree,pred.data,type="class")
  
  # Analysis:
  
    # Comparison between the result and the prediction (prediction in colunm)
    conf <- table(pred.data[,match("seller",names(pred.data))],pred)
    
    # Accurency
    acc <- sum(diag(conf)) / sum(conf)
    
  
  print(conf)
  sprintf("The accurency is : %.2f %%", acc*100)
 
}

Dtsellers()

```

```{r}
#----------------------------------------------------------------------
#                  Decision tree - CART algorithm
#   Prediction of the seller knowing the price / category / origin
#                              Results
#-----------------------------------------------------------------------

Dtsellers2 <- function(){  

  #-----------------
  #   New Data 
  #-----------------
  
  # Select all "Drugs & Chemicals" ads
  matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
  dectree.data <- data[matching_vector,]
  
  # Select the column of the data that are interesting for the tree
  # ie removing colunm like "id" or "url" that don't give any informations
  dectree.data <- subset(dectree.data, select=c(origin,category,seller,priceUnitDose))
  # Subset : choose the colunm that you want
  
  # Handling : column categorie
  # Regular expression for spliting the categories
  regex <- "/(.*)/(.*)/(.*)"
  cat <- str_match(dectree.data$category, regex)
  dectree.data$category <- cat[,3] # keep only the second part
  
  # Handling : seller
  tab_sel <- table(dectree.data$seller)
  tab_sel <- sort(tab_sel, decreasing=TRUE)  # Sorting (biggest in first)
  tab_sel <- tab_sel[1:10] # Taking only the most important : main sellers
  name_sel <- names(tab_sel)
  # New data keeping only the main sellers
  dectree.data <-subset(dectree.data, seller %in% name_sel) 
  
  # Random rows :
  dectree.data <- dectree.data[sample(nrow(dectree.data),nrow(dectree.data),replace=FALSE), ]
  
  #---------------------
  #   Decision tree
  #---------------------
  
  # Factor
  dectree.data$seller <- factor(dectree.data$seller)
  
  # Half of the data for making the decision tree
  train.data <- dectree.data[1:(floor(nrow(dectree.data))/2),]
  
  # Creation of the tree
  tree <- rpart(seller ~.,data=train.data, method="class") 

  #--------------------
  #   Prediction
  #--------------------
  
  # The other half for the prediction
  pred.data <- dectree.data[(floor(nrow(dectree.data)/2)+1):nrow(dectree.data),]
  
  # Making prediction
  pred <- predict(tree,pred.data,type="class")
  
  # Analysis:
  
    # Comparison between the result and the prediction (prediction in colunm)
    conf <- table(pred.data[,match("seller",names(pred.data))],pred)
    
    # Accurency
    acc <- sum(diag(conf)) / sum(conf)
  
  print(conf)
  sprintf("The accuracy is : %.2f %%", acc*100)
}

Dtsellers2()
```


## - Association rules

**1. Clustering of drugs**

We wondered if there were links between some drugs. That is to say, if this is possible to cluster some drugs.
To do so, firstly, we have created a new data frame with by rows sellers and by columns different sub-categories of "Drugs & Chemicals". In each cell, value is True or False if the dealer has already sold something in this sub-category or not.
Then, we have applied Apriori algorithm. We fixed one drug that must be in the itemset. Here it is Ecstasy. The result can be seen below.

```{r Ass Rules Sellers-Category}

#--------------------------------------------------------
#       Association Rules - Apriori algorithm     
#     Guess if this dealer is selling this drugs
#--------------------------------------------------------

AssRSellersCat <- function(){
  
  #------------------------------
  #  New Data frame for analysis
  #------------------------------
  
  # Select all ads of "Drugs & Chemicals"
  matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
  data_drugs <- data[matching_vector, ]
  
  # Handling of this categories
  # Regular expression for spliting the categories
  regex <- "/(.*)/(.*)/(.*)"
  cat_exp <- str_match(data_drugs$category, regex)
  data_drugs$category <- cat_exp[,3]
  
  # Get rid of category "Other"
  matching_vector <- !c( str_detect(data_drugs$category, "Other"))
  data_drugs <- data_drugs[matching_vector, ]
  
  # List all the sellers
  sellers <-sort(table(data_drugs$seller), decreasing = TRUE)
  sellers <- sellers[ sellers != "Null"]
  sellers <- sellers [1:100]
  
  #List all categories concerning drugs
  list_category <- table(data_drugs[,"category"])
  list_cat_drugs <- list_category [ list_category != 0]
  
# Step 1 : initialise a data.frame with the information of the first seller
  
  # Select all categories of the seller  
  matching_vector <- c( str_detect(data$seller, names(sellers)[1]))
  cat_seller <-summary(data.frame(data[matching_vector, "category"]))
  
  # Loop which creates a boolean vector which tells if the seller sells stuffs in each category 
  bool_cat <-c()
  bool_vec <-c()
  for( i in 1: length(list_cat_drugs)){
    bool_vec <- str_detect(cat_seller, names(list_cat_drugs)[i])
    
    bool <- FALSE 
    for(j in 1:length(bool_vec)){
      bool <- bool || bool_vec[j]
    }
    bool_cat[i] <- bool
    
  }
  
  cat_seller.data <- t(data.frame(bool_cat))
  colnames(cat_seller.data) <- names(list_cat_drugs)
  
#Step 2 : Do the same for the other sellers
  
  for(k in 2 : length(sellers)){
    # Select all categories of the seller  
    matching_vector <- c( str_detect(data$seller, names(sellers)[k]))
    cat_seller <-summary(data.frame(data[matching_vector, "category"]))
    
    # Loop which creates a boolean vector which tells if the seller sells stuffs in each category 
    bool_cat <-c()
    bool_vec <-c()
    for( i in 1: length(list_cat_drugs)){
      bool_vec <- str_detect(cat_seller, names(list_cat_drugs)[i])
      
      bool <- FALSE 
      for(j in 1:length(bool_vec)){
        bool <- bool || bool_vec[j]
      }
      bool_cat[i] <- bool
      
    }
    
    cat_seller.data <- rbind(cat_seller.data,bool_cat)
    
  }
  
  rownames(cat_seller.data)<- names(sellers)

  #-------------------------
  #      Ass Rules
  #-------------------------
  
  # Association Rules with rhs containing "Ecstasy" only
  rules <- apriori(cat_seller.data,
                   parameter = list(minlen=2, supp=0.05, conf=0.8),
                   appearance = list(rhs=c("Ecstasy"),default="lhs"),
                   control = list(verbose=F))
  
  rules.sorted <- sort(rules, by="lift")
  inspect(rules.sorted, linebreak = TRUE)
  
  # Plot graph of rules
  plot(rules.sorted[1:5], method="graph", control=list(type="items"),main ="")
  mtext("Association Rules on the product range of sellers" , cex = 1.2)
  
  # Frame
  box(which = "outer", lty = "solid")

}

AssRSellersCat()

```

The algorithm succeeds in finding some rules in the data frame. That means that some drugs can effectively be clustered. The support is between 5% and 15% so it is frequent to have these itemsets. Moreover the confidence is more than 80%. In other words, if we have the itemset on the left we are most likely to have the drug on the right. 
We can interpret from these rules that sellers often deal more than one product. And these products can be clustered by type.

**2. Rules to determine cateogries of ads coming from United States** 

Secondly, we ran the algorithm with 2 variables : category and origin. Thus, we may be able to make a link with predictions of above decision tree. We fixed one country, here United States. 


```{r Ass Rules Origin}
#--------------------------------------------------------
#       Association Rules - Apriori algorithm     
#     Guess if United States is the origin of the ad
#--------------------------------------------------------

AssROriginSellerCat <- function(){  
  #------------------------------
  #  New Data frame for analysis
  #------------------------------

  # Select all ads of "Drugs & Chemicals"
  matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
  data_drugs <- data[matching_vector, ]
  
  # Select some columns
  asso.data <- subset(data_drugs, select = c(origin,category))
  
  # Get rid of the first part of the category name "/Drugs & Chemicals/"
  asso.data$category <- gsub(pattern = "/Drugs & Chemicals/", replacement = "", asso.data$category)
  
  asso.data$origin <- factor(asso.data$origin)
  asso.data$category <-factor(asso.data$category)
  # asso.data$seller <- factor(asso.data$seller)
  
  # Association Rules with rhs containing one given country only
  rules <- apriori(asso.data,
                   parameter = list(minlen=2, supp=0.002, conf=0.5),
                   appearance = list(rhs=c("origin=United States"),default="lhs"),
                   control = list(verbose=F))
  
  rules.sorted <- sort(rules, by="lift")
  inspect(rules.sorted, linebreak = TRUE)
  
  # Plot graph of rules
  plot(rules.sorted, method="graph", control=list(type="items"),main ="")
  mtext("Association Rules on the category and seller to deduce the country" , cex = 1.2)
  
  # Frame
  box(which = "outer", lty = "solid")

}

AssROriginSellerCat()

```
The results show that when we have an ad of the categories on the left, it is likely to come from United States with a confidence higher than 50%. Thus, ads from United States are often on Cannabis & Hashish, this can be easily confirmed by plotting a pie chart of United States exportations, as in the section before. 

It is striking to see that Cannabis & Hashish seems to be the main rule. This can be explained by the legalisation of Cannibis in some states. Thus, the sales of these products is easy in United States and may interest people from other countries where they are not legalized. 

## - Bayesian classification

We used Bayesian Classification in the same objective as desicion tree : predicting something.

**1. Naive alogrithm** 

First, we ran Naive algorithm on the data base with by rows ads and by columns origin,category,seller,priceUnitDose, products_sold and sold_since. The aim is to predict who is the seller of each ads.We select only the main sellers because, the remaining just own few ads. We train the algorithm with half of the data and made predictions on other half. Results can be found below.

```{r Bayesian Sellers}
#----------------------------------------------------------------------------------
#                       Bayesian Classification - Naive
#   Prediction of the Seller knowing the origin / price / category / products_sold
#-----------------------------------------------------------------------------------

BayesSellers <- function(){
  #-----------------
  #   New Data 
  #-----------------
  
  # Select all "Drugs & Chemicals" ads
  matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
  bayesian.data <- data[matching_vector,]
  
  # Select the column of the data that are interesting
  # ie removing colunm like "id" or "url" that don't give any informations
  bayesian.data <- subset(bayesian.data, select=c(origin,category,seller,priceUnitDose, products_sold, sold_since ))
  # Subset : choose the colunm that you want
  
  # Handling : column category
  # Regular expression for spliting the categories
  regex <- "/(.*)/(.*)/(.*)"
  cat <- str_match(bayesian.data$category, regex)
  bayesian.data$category <- cat[,3] # keep only the second part
  
  sellers <- names(sort(table(bayesian.data$seller), decreasing = TRUE))[1:10]
  
  bayesian.data <-subset(bayesian.data, seller %in% sellers)
  
  bayesian.data$seller <- factor(bayesian.data$seller, labels = sellers)

  #---------------------
  #   Bayesian stat
  #---------------------
  
  # Random rows :
  bayesian.data <- bayesian.data[sample(nrow(bayesian.data),nrow(bayesian.data),replace=FALSE), ]
  
  train.data <- bayesian.data[1:floor(nrow(bayesian.data)/2),]
  pred.data <- bayesian.data[(floor(nrow(bayesian.data)/2)+1):nrow(bayesian.data),]
  
  model <- naiveBayes(seller ~ ., data =  train.data)
  
  
  preds <- predict(model, newdata = pred.data)
  conf_matrix <- table(preds, pred.data$seller)
  acc <- round(sum(diag(conf_matrix)) / sum(conf_matrix)*100, 2)
  
  print(conf_matrix)
  
  
  return(acc)
}

acc <- BayesSellers()
sprintf("The accuracy is : %.2f %%", acc)
```
Results show that the algorithm succeeds in predicting most of the sellers. Actually the accuracy is `r acc`%. Which is a little bit less than with decision tree. However with more sellers (i.e more than 40 sellers), this algorithm tends to be more accurate than decision trees.

**2. Bayesian Neural Network** 

Secondly, we wanted to predict the profitability of an ad. That is to say, given an ad to predict if it will be sold a lot or not. Each ad have information on the category, origin, seller, price and a rate of profitability. This rate is caculated by dividing the number of product sold by the current lifetime of the ad and by times 30 to have a number of ads sold monthly. We ran Bayesian Neural Network algorithm on this new data and we obtained the results below.

```{r Bayesian Network}
#----------------------------------------------------------------------
#                       Bayesian Network
#    with seller / origin / price / category / timestamp / sold_since / product_sold
#-----------------------------------------------------------------------

BayesNet <- function(){
  #-----------------
  #   New Data 
  #-----------------
  
  # Select all "Drugs & Chemicals" ads
  matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
  bayesian.data <- data[matching_vector,]
  
  
  # Select the column of the data that are interesting
  # ie removing colunm like "id" or "url" that don't give any information
  bayesian.data <- subset(bayesian.data, select=c(origin,category,seller,priceUnitDose, products_sold, sold_since, timestamp ))
  # Subset : choose the colunm that you want
  
  # Handling : column category
  # Regular expression for spliting the categories
  regex <- "/(.*)/(.*)/(.*)"
  cat <- str_match(bayesian.data$category, regex)
  bayesian.data$category <- cat[,3] # keep only the second part
  
  #Get rid of lines with Null as products_sold value
  bayesian.data <- bayesian.data[!is.element(bayesian.data$products_sold, "NULL"),]
  
  #Convert products_sold to numeric and discretize it
  bayesian.data$products_sold <- as.numeric(as.character(bayesian.data$products_sold))
  
  #Given timestamp and sold_since calculate the lifetime of the ad
  bayesian.data$sold_since <-  as.Date(bayesian.data$sold_since)
  bayesian.data$timestamp <-  as.Date(bayesian.data$timestamp)
  bayesian.data$timestamp <- bayesian.data$timestamp - bayesian.data$sold_since
  bayesian.data$timestamp <- as.numeric(bayesian.data$timestamp)
  
  # 1 day on the market at least
  bayesian.data <- bayesian.data[which(bayesian.data$timestamp > 0),]
  
  #Calculate profitability
  bayesian.data$products_sold <- bayesian.data$products_sold / bayesian.data$timestamp * 30
  names(bayesian.data)[match("products_sold",names(bayesian.data))] <- "profitability"
  
  #Discretize profitability
  bayesian.data$profitability <- arules::discretize(bayesian.data$profitability, method="frequency", categories = 5)
  
  bayesian.data <- subset(bayesian.data, select= -c(sold_since, timestamp))
  
  #Convert variables to factor
  bayesian.data$category <- as.factor(bayesian.data$category)
  bayesian.data$seller <- as.factor(bayesian.data$seller)
  bayesian.data$origin <- as.factor(bayesian.data$origin)
  
  #Get rid of lines with NA as products_sold value
  bayesian.data <- bayesian.data[!is.element(bayesian.data$profitability, NA),]
  
  #---------------------
  #   Bayesian Network
  #---------------------
  
  res <- hc(bayesian.data)
  plot(res)
  
  fittedbn <- bn.fit(res, data = bayesian.data)
  
  print(fittedbn$profitability)
  
  #Handling interval
  interv <- levels(bayesian.data$profitability)
  interv <- unlist(strsplit(interv, ","))
  interv <- gsub(pattern = "[^0-9.]*", replacement = "", interv)
  interval <- data.frame(interv[seq(1, length(interv), 2)],interv[seq(2, length(interv), 2)])
  colnames(interval) <- c("left", "right")
  interval$left <- as.numeric(levels(interval$left))
  interval$right <- as.numeric(levels(interval$right))
  
  expectancy <- c()
  #Calculate expectancy for each category 
  for(i in 0:(length(table(bayesian.data$category))-1)){
    left <- 0
    right <- 0
    for(j in 1:nbCategory){
      left<-left + interval$left[j] * fittedbn$profitability$prob[i*nbCategory + j]
      right<-right + interval$right[j] * fittedbn$profitability$prob[i*nbCategory + j]
    }
    expectancy[i+1] <- paste("[", round(left,2) , "," , round(right,2) , "]")
    affichage <-paste(names(table(bayesian.data$category))[i+1],"expectancy :", expectancy[i+1])
    print(affichage)
  }


}

BayesNet()
```

Neural Network shows that the profitability is conditionnaly dependant to category. That is to say category have a significant impact on profitability. Conditional probabilities are shown in the array. It is surprising that price and seller have no impacts on profitability.  

# - References
***

