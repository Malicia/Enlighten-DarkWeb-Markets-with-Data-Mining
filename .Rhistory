# Loop which creates a boolean vector which tells if the seller sells stuffs in each category
bool_cat <-c()
bool_vec <-c()
for( i in 1: length(list_cat_drugs)){
bool_vec <- str_detect(cat_seller, names(list_cat_drugs)[i])
bool <- FALSE
for(j in 1:length(bool_vec)){
bool <- bool || bool_vec[j]
}
bool_cat[i] <- bool
}
cat_seller.data <- t(data.frame(bool_cat))
colnames(cat_seller.data) <- names(list_cat_drugs)
#Step 2 : Do the same for the other sellers
for(k in 2 : length(sellers)){
# Select all categories of the seller
matching_vector <- c( str_detect(data$seller, names(sellers)[k]))
cat_seller <-summary(data.frame(data[matching_vector, "category"]))
# Loop which creates a boolean vector which tells if the seller sells stuffs in each category
bool_cat <-c()
bool_vec <-c()
for( i in 1: length(list_cat_drugs)){
bool_vec <- str_detect(cat_seller, names(list_cat_drugs)[i])
bool <- FALSE
for(j in 1:length(bool_vec)){
bool <- bool || bool_vec[j]
}
bool_cat[i] <- bool
}
cat_seller.data <- rbind(cat_seller.data,bool_cat)
}
rownames(cat_seller.data)<- names(sellers)
#-------------------------
#      Ass Rules
#-------------------------
# Association Rules with rhs containing "Ecstasy" only
rules <- apriori(cat_seller.data,
parameter = list(minlen=2, supp=0.05, conf=0.8),
appearance = list(rhs=c("Ecstasy"),default="lhs"),
control = list(verbose=F))
rules.sorted <- sort(rules, by="lift")
rules.sorted@quality$support <- round(rules.sorted@quality$support, 3)
rules.sorted@quality$confidence <- round(rules.sorted@quality$confidence, 2)
rules.sorted@quality$lift <- round(rules.sorted@quality$lift, 2)
inspect(rules.sorted, linebreak = TRUE)
# Plot graph of rules
plot(rules.sorted[1:5], method="graph", control=list(type="items"),main ="")
mtext("Association Rules on the product range of sellers" , cex = 1.2)
# Frame
box(which = "outer", lty = "solid")
}
AssRSellersCat()
#----------------------------------------------------------------------
#                  Decision tree - CART algorithm
#   Prediction of the country knowing the seller / price / category
#-----------------------------------------------------------------------
DTorigin <- function(){
#-----------------
#   New Data
#-----------------
# Select all "Drugs & Chemicals" ads
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
dectree.data <- data[matching_vector,]
# Select the column of the data that are interesting for the tree
# ie removing colunm like "id" or "url" that don't give any informations
dectree.data <- subset(dectree.data, select=c(origin,category,seller,priceUnitDose))
# Subset : choose the colunm that you want
# Handling : column categorie
# Regular expression for spliting the categories
regex <- "/(.*)/(.*)/(.*)"
cat <- str_match(dectree.data$category, regex)
dectree.data$category <- cat[,3] # keep only the second part
# Handling : country
dectree.data <- dectree.data[which(dectree.data$origin != "Worldwide"),]
tab_coun <- table(dectree.data$origin)
tab_coun <- sort(tab_coun, decreasing=TRUE)  # Sorting (biggest in first)
tab_coun <- tab_coun[1:15] # Taking only the most important : main sellers
name_coun <- names(tab_coun)
# New data keeping only the main dealers
dectree.data <-subset(dectree.data, origin %in% name_coun)
# Handling : seller
tab_sel <- table(dectree.data$seller)
tab_sel <- sort(tab_sel, decreasing=TRUE)  # Sorting (biggest in first)
tab_sel <- tab_sel[1:7] # Taking only the most important : main sellers
name_sel <- names(tab_sel)
# New data keeping only the main sellers
dectree.data <-subset(dectree.data, seller %in% name_sel)
# Random rows :
dectree.data <- dectree.data[sample(nrow(dectree.data),nrow(dectree.data),replace=FALSE), ]
#---------------------
#   Decision tree
#---------------------
# Factor
dectree.data$origin <- factor(dectree.data$origin)
# Half of the data for making the decision tree
train <- dectree.data[1:(floor(nrow(dectree.data))/2),]
# Creation of the tree
tree <- rpart(origin ~.,data=train, method="class")
# Plot
fancyRpartPlot(tree)
# Frame
box(which = "outer", lty = "solid")
#--------------------
#   Prediction
#--------------------
# The other half for the prediction
test <- dectree.data[(floor(nrow(dectree.data)/2)+1):nrow(dectree.data),]
# Making prediction
pred <- predict(tree,test,type="class")
# Analysis:
# Comparison between the result and the prediction (prediction in colunm)
conf <- table(test[,match("origin",names(test))],pred)
# Accuracy :
acc <- sum(diag(conf)) / sum(conf)
print(conf)
print(acc)
}
DTorigin()
#--------------------------------------------------------
#       Association Rules - Apriori algorithm
#     Guess if United States is the origin of the ad
#--------------------------------------------------------
AssROriginSellerCat <- function(){
#------------------------------
#  New Data frame for analysis
#------------------------------
# Select all ads of "Drugs & Chemicals"
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
data_drugs <- data[matching_vector, ]
# Select some columns
asso.data <- subset(data_drugs, select = c(origin,category))
# Get rid of the first part of the category name "/Drugs & Chemicals/"
asso.data$category <- gsub(pattern = "/Drugs & Chemicals/", replacement = "", asso.data$category)
asso.data$origin <- factor(asso.data$origin)
asso.data$category <-factor(asso.data$category)
# asso.data$seller <- factor(asso.data$seller)
# Association Rules with rhs containing one given country only
rules <- apriori(asso.data,
parameter = list(minlen=2, supp=0.0005, conf=0.5),
appearance = list(rhs=c("origin=United States"),default="lhs"),
control = list(verbose=F))
rules.sorted <- sort(rules, by="lift")
rules.sorted@quality$support <- round(rules.sorted@quality$support, 3)
rules.sorted@quality$confidence <- round(rules.sorted@quality$confidence, 2)
rules.sorted@quality$lift <- round(rules.sorted@quality$lift, 2)
inspect(rules.sorted)
# Plot graph of rules
plot(rules.sorted, method="graph", control=list(type="items"),main ="")
mtext("Association Rules on the category and seller to deduce the country" , cex = 1.2)
# Frame
box(which = "outer", lty = "solid")
}
AssROriginSellerCat()
#----------------------------------------------------------------------
#                       Bayesian Network
#    with seller / origin / price / category / timestamp / sold_since / product_sold
#-----------------------------------------------------------------------
BayesNet <- function(){
#-----------------
#   New Data
#-----------------
# Select all "Drugs & Chemicals" ads
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
bayesian.data <- data[matching_vector,]
# Select the column of the data that are interesting
# ie removing colunm like "id" or "url" that don't give any information
bayesian.data <- subset(bayesian.data, select=c(origin,category,seller,priceUnitDose, products_sold, sold_since, timestamp ))
# Subset : choose the colunm that you want
# Handling : column category
# Regular expression for spliting the categories
regex <- "/(.*)/(.*)/(.*)"
cat <- str_match(bayesian.data$category, regex)
bayesian.data$category <- cat[,3] # keep only the second part
#Get rid of lines with Null as products_sold value
bayesian.data <- bayesian.data[!is.element(bayesian.data$products_sold, "NULL"),]
#Convert products_sold to numeric and discretize it
bayesian.data$products_sold <- as.numeric(as.character(bayesian.data$products_sold))
#Given timestamp and sold_since calculate the lifetime of the ad
bayesian.data$sold_since <-  as.Date(bayesian.data$sold_since)
bayesian.data$timestamp <-  as.Date(bayesian.data$timestamp)
bayesian.data$timestamp <- bayesian.data$timestamp - bayesian.data$sold_since
bayesian.data$timestamp <- as.numeric(bayesian.data$timestamp)
# 1 day on the market at least
bayesian.data <- bayesian.data[which(bayesian.data$timestamp > 0),]
#Calculate profitability
bayesian.data$products_sold <- bayesian.data$products_sold / bayesian.data$timestamp * 30
names(bayesian.data)[match("products_sold",names(bayesian.data))] <- "profitability"
#Discretize profitability
nbCategory <- 5
bayesian.data$profitability <- arules::discretize(bayesian.data$profitability, method="frequency", categories = nbCategory)
bayesian.data <- subset(bayesian.data, select= -c(sold_since, timestamp))
#Convert variables to factor
bayesian.data$category <- as.factor(bayesian.data$category)
bayesian.data$seller <- as.factor(bayesian.data$seller)
bayesian.data$origin <- as.factor(bayesian.data$origin)
#Get rid of lines with NA as products_sold value
bayesian.data <- bayesian.data[!is.element(bayesian.data$profitability, NA),]
#---------------------
#   Bayesian Network
#---------------------
res <- hc(bayesian.data)
plot(res)
fittedbn <- bn.fit(res, data = bayesian.data)
print(fittedbn$profitability)
#Handling interval
interv <- levels(bayesian.data$profitability)
interv <- unlist(strsplit(interv, ","))
interv <- gsub(pattern = "[^0-9.]*", replacement = "", interv)
interval <- data.frame(interv[seq(1, length(interv), 2)],interv[seq(2, length(interv), 2)])
colnames(interval) <- c("left", "right")
interval$left <- as.numeric(levels(interval$left))
interval$right <- as.numeric(levels(interval$right))
expectancy <- c()
#Calculate expectancy for each category
for(i in 0:(length(table(bayesian.data$category))-1)){
left <- 0
right <- 0
for(j in 1:nbCategory){
left<-left + interval$left[j] * fittedbn$profitability$prob[i*nbCategory + j]
right<-right + interval$right[j] * fittedbn$profitability$prob[i*nbCategory + j]
}
expectancy[i+1] <- paste("[", round(left,2) , "," , round(right,2) , "]")
affichage <-paste(names(table(bayesian.data$category))[i+1],"expectancy :", expectancy[i+1])
print(affichage)
}
# Frame
box(which = "outer", lty = "solid")
mtext("Dependency between informations" , cex = 1.2,side = 1)
}
BayesNet()
#----------------------------------------------------------------------
#                       Bayesian Network
#    with seller / origin / price / category / timestamp / sold_since / product_sold
#-----------------------------------------------------------------------
BayesNet <- function(){
#-----------------
#   New Data
#-----------------
# Select all "Drugs & Chemicals" ads
matching_vector <- c( str_detect(data$category, "Drugs & Chemicals"))
bayesian.data <- data[matching_vector,]
# Select the column of the data that are interesting
# ie removing colunm like "id" or "url" that don't give any information
bayesian.data <- subset(bayesian.data, select=c(origin,category,seller,priceUnitDose, products_sold, sold_since, timestamp ))
# Subset : choose the colunm that you want
# Handling : column category
# Regular expression for spliting the categories
regex <- "/(.*)/(.*)/(.*)"
cat <- str_match(bayesian.data$category, regex)
bayesian.data$category <- cat[,3] # keep only the second part
#Get rid of lines with Null as products_sold value
bayesian.data <- bayesian.data[!is.element(bayesian.data$products_sold, "NULL"),]
#Convert products_sold to numeric and discretize it
bayesian.data$products_sold <- as.numeric(as.character(bayesian.data$products_sold))
#Given timestamp and sold_since calculate the lifetime of the ad
bayesian.data$sold_since <-  as.Date(bayesian.data$sold_since)
bayesian.data$timestamp <-  as.Date(bayesian.data$timestamp)
bayesian.data$timestamp <- bayesian.data$timestamp - bayesian.data$sold_since
bayesian.data$timestamp <- as.numeric(bayesian.data$timestamp)
# 1 day on the market at least
bayesian.data <- bayesian.data[which(bayesian.data$timestamp > 0),]
#Calculate profitability
bayesian.data$products_sold <- bayesian.data$products_sold / bayesian.data$timestamp * 30
names(bayesian.data)[match("products_sold",names(bayesian.data))] <- "profitability"
#Discretize profitability
nbCategory <- 5
bayesian.data$profitability <- arules::discretize(bayesian.data$profitability, method="frequency", categories = nbCategory)
bayesian.data <- subset(bayesian.data, select= -c(sold_since, timestamp))
#Convert variables to factor
bayesian.data$category <- as.factor(bayesian.data$category)
bayesian.data$seller <- as.factor(bayesian.data$seller)
bayesian.data$origin <- as.factor(bayesian.data$origin)
#Get rid of lines with NA as products_sold value
bayesian.data <- bayesian.data[!is.element(bayesian.data$profitability, NA),]
#---------------------
#   Bayesian Network
#---------------------
res <- hc(bayesian.data)
plot(res)
fittedbn <- bn.fit(res, data = bayesian.data)
print(fittedbn$profitability)
#Handling interval
interv <- levels(bayesian.data$profitability)
interv <- unlist(strsplit(interv, ","))
interv <- gsub(pattern = "[^0-9.]*", replacement = "", interv)
interval <- data.frame(interv[seq(1, length(interv), 2)],interv[seq(2, length(interv), 2)])
colnames(interval) <- c("left", "right")
interval$left <- as.numeric(levels(interval$left))
interval$right <- as.numeric(levels(interval$right))
expectancy <- c()
#Calculate expectancy for each category
for(i in 0:(length(table(bayesian.data$category))-1)){
left <- 0
right <- 0
for(j in 1:nbCategory){
left<-left + interval$left[j] * fittedbn$profitability$prob[i*nbCategory + j]
right<-right + interval$right[j] * fittedbn$profitability$prob[i*nbCategory + j]
}
expectancy[i+1] <- paste("[", round(left,2) , "," , round(right,2) , "]")
affichage <-paste(names(table(bayesian.data$category))[i+1],"expectancy :", expectancy[i+1])
print(affichage)
}
# Frame
box(which = "outer", lty = "solid")
mtext("Conditional dependency between variables" , cex = 1.2,side = 1)
}
BayesNet()
source('~/.active-rstudio-document')
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
data$title[1]
class(data$title)
levels(data$title)
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
wordsOfCurrentAds[1]
data$title[1]
source('~/UEL-project/More stats/analysisWords.R')
words
wordsOfCurentAds[1][1]
wordsOfCurrentAds[1][1]
wordsOfCurrentAds[1,1]
wordsOfCurrentAds[1 1]
wordsOfCurrentAds[1.1]
wordsOfCurrentAds[1,1]
(wordsOfCurrentAds[1])[1]
(wordsOfCurrentAds[[1]]
)
source('~/UEL-project/More stats/analysisWords.R')
str_split(data$title[1], boundary("word"))
str_split(data$title[5], boundary("word"))
str_split(data$title[4], boundary("word"))
str_split(data$title[3], boundary("word"))
str_split(data$title[2], boundary("word"))
str_split(data$title[1], boundary("word"))
wordsOfCurrentAds <- str_split(data$title, boundary("word"))
summary(wordsOfCurrentAds)
wordsOfCurrentAds[1,]
wordsOfCurrentAds[1
]
class(wordsOfCurrentAds[1])
class(wordsOfCurrentAds)
wordsOfCurrentAds <- unlist(str_split(data$title, boundary("word")))
words.vector <- str_split(data$title, boundary("word"))
summary(unlist(words.vector))
table(unlist(words.vector))
source('~/UEL-project/More stats/analysisWords.R')
tableWords
tableWords[1]
tableWords[2]
tableWords[3]
tableWords[7]
tableWords[2000]
print(tableWords)
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
tableWords
length(tableWords[1])
size(tableWords[1])
class(tableWords[1])
class(names(tableWords[1]))
length(names(tableWords[1]))
size(names(tableWords[1]))
words.cat.list <- str_split(data$category, "/")
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
setwd("~/UEL-project")
source('~/UEL-project/More stats/analysisWords.R')
source('~/UEL-project/More stats/analysisWords.R')
words.cat.list
source('~/UEL-project/More stats/analysisWords.R')
tableWords <- sort(table(rbind(unlist(words.ad.list),unlist(words.cat.list) )), decreasing = TRUE)
words.title.list <- str_split(data$title, boundary("word"))
#words.brief.list <- str_split(data$brief, boundary("word"))
#words.ad.list <- str_split(data$title, boundary("word"))
words.cat.list <- str_split(data$category, "/")
tableWords <- sort(table(rbind(unlist(words.ad.list),unlist(words.cat.list) )), decreasing = TRUE)
unlist(words.ad.list)
unlist(words.cat.list)
word.cat.vector <- unlist(words.cat.list)
word.cat.vector <- sort(table(word.cat.vector, decreasing = TRUE))
word.cat.vector <- sort(table(word.cat.vector), decreasing = TRUE)
word.cat.vector
rbind(unlist(words.cat.list), word.cat.vector)
rbind(as.vector(unlist(words.cat.list)), as.vector(word.cat.vector))
as.vector(word.cat.vector)
words.title.list <- str_split(data$title, boundary("word"))
#words.brief.list <- str_split(data$brief, boundary("word"))
#words.ad.list <- str_split(data$title, boundary("word"))
words.cat.list <- str_split(data$category, "/")
word.cat.vector <- unlist(words.cat.list)
rbind(as.vector(unlist(words.cat.list)), as.vector(word.cat.vector))
words
words
as.vector(unlist(words.cat.list))
as.vector(word.cat.vector)
as.vector(unlist(words.title.list)
)
words <- rbind(as.vector(unlist(words.title.list)), as.vector(word.cat.vector))
tableWords <- sort(table(words), decreasing = TRUE)
as.vector(unlist(words.title.list))
as.vector(word.cat.vector
)
words <- rbind(as.vector(unlist(words.title.list)), as.vector(word.cat.vector))
source('~/UEL-project/More stats/analysisWords.R')
words <- rbind(as.data.frame(unlist(words.title.list)), as.data.frame(word.cat.vector))
#-----------------------------------------------
#       Words analysis
#-----------------------------------------------
#data <- as.data.frame(read.csv("../alphaClean.csv"))
library(stringr)
# Pick up every words
words.title.list <- str_split(data$title, boundary("word"))
#words.brief.list <- str_split(data$brief, boundary("word"))
#words.ad.list <- str_split(data$title, boundary("word"))
words.cat.list <- str_split(data$category, "/")
word.cat.vector <- unlist(words.cat.list)
#word.cat.vector <- sort(table(word.cat.vector), decreasing = TRUE)
words <- rbind(as.data.frame(unlist(words.title.list)), as.data.frame(word.cat.vector))
as.data.frame(unlist(words.title.list)
)
data <- as.data.frame(read.csv("../alphaClean.csv"))
library(stringr)
# Pick up every words
words.title.list <- str_split(data$title, boundary("word"))
#words.brief.list <- str_split(data$brief, boundary("word"))
#words.ad.list <- str_split(data$title, boundary("word"))
words.cat.list <- str_split(data$category, "/")
word.cat.vector <- unlist(words.cat.list)
#word.cat.vector <- sort(table(word.cat.vector), decreasing = TRUE)
word.cat.vector
word.cat.vector <- as.vector(unlist(words.cat.list))
x <- c(3,2,1)
y<- c(1,2,3)
rbind(x,y)
rbind(t(x),t(y))
colbind(t(x),t(y))
cbind(x,y)
words <- c(unlist(words.title.list), word.cat.vector)
source('~/UEL-project/More stats/analysisWords.R')
data <- as.data.frame(read.csv("../alphaClean.csv"))
library(stringr)
# Pick up every words
words.title.list <- str_split(data$title, boundary("word"))
#words.brief.list <- str_split(data$brief, boundary("word"))
#words.ad.list <- str_split(data$title, boundary("word"))
words.cat.list <- str_split(data$category, "/")
word.cat.vector <- as.vector(unlist(words.cat.list))
#word.cat.vector <- sort(table(word.cat.vector), decreasing = TRUE)
words <- c(unlist(words.title.list), word.cat.vector)
tableWords <- sort(table(words), decreasing = TRUE)
tableWords
words <- c(unlist(words.title.list), str_to_lower(word.cat.vector))
tableWords <- sort(table(words), decreasing = TRUE)
tableWords <- as.data.frame(tableWords)
View(tableWords)
View(tableWords)
tableWords <- sort(table(words), decreasing = TRUE)
tableWords <- as.data.frame(tableWords)
tableWords$words <- as.character(tableWords$words)
# Removing all words containing less than 2 letters
tableWords <- tableWords[str_count(tableWords[,1], "")>2,]
# Removing conjonction, preposition, ??numbers??
commonWords <- read.csv("./More Stats/commonWords.csv")
commonWords <- as.vector(commonWords$Word)
commonWords <- str_trim(commonWords)
tableWords <-subset(tableWords, !( words %in% commonWords))
View(tableWords)
View(tableWords)
nrow(data)/5000
tableWords <- tableWords[which(tableWords$Freq > nrow(data)/5000), ]
View(tableWords)
View(tableWords)
str_detect(tableWords, "^[0-9]*$")
str_detect(tableWords$words, "^[0-9]*$")
View(tableWords)
View(tableWords)
View(tableWords)
View(tableWords)
tableWords <- tableWords[str_detect(tableWords$words, "^[0-9]*$"),]
library(stringr)
# Pick up every words
words.title.list <- str_split(data$title, boundary("word"))
#words.brief.list <- str_split(data$brief, boundary("word"))
#words.ad.list <- str_split(data$title, boundary("word"))
words.cat.list <- str_split(data$category, "/")
word.cat.vector <- as.vector(unlist(words.cat.list))
#word.cat.vector <- sort(table(word.cat.vector), decreasing = TRUE)
words <- c(unlist(words.title.list), str_to_lower(word.cat.vector))
tableWords <- sort(table(words), decreasing = TRUE)
tableWords <- as.data.frame(tableWords)
tableWords$words <- as.character(tableWords$words)
# Removing all words containing less than 2 letters
tableWords <- tableWords[str_count(tableWords[,1], "")>2,]
# Removing conjonction, preposition, ??numbers??
commonWords <- read.csv("./More Stats/commonWords.csv")
commonWords <- as.vector(commonWords$Word)
commonWords <- str_trim(commonWords)
tableWords <-subset(tableWords, !( words %in% commonWords))
tableWords <- tableWords[!str_detect(tableWords$words, "^[0-9]*$"),]
tableWords <- tableWords[which(tableWords$Freq > nrow(data)/5000), ]
words.cat.list
View(data)
View(data)
commonWords
